vol_r <- colSds(x)
#returning the standard deviations of the columns
return(vol_r)
}
#Creating a matrix of the returns
ALL.r <- exrates.xts[, 1:4]
#Creating a window of 90 days
window <- 90  #reactive({input$window})
#rollapply is applying the corr_rolling function to the All.r data frame
#on a rolling window of 90 days on each column individually
corr_r <- rollapply(ALL.r, width = window,
corr_rolling, align = "right", by.column = FALSE)
#Assigning the column names to the correlations between the columns
colnames(corr_r) <- c("EUR.GBP", "EUR.CNY",
"EUR.JPY", "GBP.CNY", "GBP.JPY",
"CNY.JPY")
#rollapply is applying the vol_rolling function to the All.r data frame
#on a rolling window of 90 days on each column individually
vol_r <- rollapply(ALL.r, width = window,
vol_rolling, align = "right", by.column = FALSE)
#assigning the column names to the vol_r data frame
colnames(vol_r) <- c("EUR.vol", "GBP.vol",
"CNY.vol", "JPY.vol")
#creating a vector that takes the year from the index and just extracts the year
year <- format(index(corr_r), "%Y")
#combining the data frames for the returns, rolling returns correlation, rolling
#volatility correlation, and the year for the date
r_corr_vol <- merge(ALL.r, corr_r, vol_r,
year)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating a vector from 0.05 to 0.95 in which the regression will attempt
#to reduce error from that given quantile at a given x
taus <- seq(0.05, 0.95, 0.05)  # Roger Koenker UIC Bob Hogg and Allen Craig
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating
fit.lm.CNY.JPY <- lm(log(CNY.JPY) ~ log(JPY.vol),
data = r_corr_vol)
.
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#importing the quantile regression library
library(quantreg)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating
fit.lm.CNY.JPY <- lm(log(CNY.JPY) ~ log(JPY.vol),
data = r_corr_vol)
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
CNY.JPY.summary
CNY.JPY.summary <- summary(fit.lm.CNY.JPY,
se = "boot")
CNY.JPY.summary
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
CNY.JPY.summary
library(quantreg)
library(magick)
?image_graph
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
geom_quantile(quantiles = c(0.05,
0.95)) + geom_quantile(quantiles = 0.5,
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_quantile
p <- ggplot(data, aes(JPY.vol, CNY.JPY))
mtcars
cars <- mtcars
p <- ggplot(cars, aes(wt, mpg))
?geom_density2d
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
geom_quantile(quantiles = c(0.05,
0.95)) + geom_quantile(quantiles = 0.5,
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_density
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_density_2d
?dev.off
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(log(JPY.vol), log(CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the regression
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(log(JPY.vol), log(CNY.JPY))) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?dev.list
dev.list(()\)
dev.list()
?magick
?image_graph
?image_animate
knitr::opts_chunk$set(echo = TRUE)
library(zoo)      #For creating time series objects
library(xts)      #For time series analysis
library(ggplot2)  #For creating graphics
library(plotly)
#The URL for the exchange data data
URL <- "https://turing.manhattan.edu/~wfoote01/finalytics/data/exrates.csv"
#Reading in the exchange rates and omitting the missing data from the
#url provided by turing.manhattan.edu and keeping the dates as characters
exrates <- na.omit(read.csv("exrates.csv", stringsAsFactors = F))
#Converting the string dates to actual dates
exrates$DATE <- as.Date(exrates$DATE, "%m/%d/%Y")
#Five columns (date, eur2usd, gbp2usd, cny2usd, jpy2usd)
#the data is daily exchange rates
head(exrates)     #Looking at the data
tail(exrates)     #Looking at the end of the data
str(exrates)      #Viewing the structure of the data
#1253 different instances of exchange rates
summary(exrates)  #From 28 Jan 2013 to 26 Jan 2018
# USD to CNY appears to be the most steady
#Using the properties of the natural log to determine
#the percent change in exchange rates
exrates.r <- diff(log(as.matrix(exrates[,-1]))) * 100
head(exrates.r)   #first 6 days of percent change
tail(exrates.r)   #last 6 days of percent change
str(exrates.r)    #Shows there are 4 columns with 1252 instances
#creating a matrix for the volatility of the exchange markets
size <- na.omit(abs(exrates.r))
head(size)        #viewing the first 6 rows of the size matrix
#Creating a vector of names for the matrix that has the same name as
#the exrates matrix, but with ".size" appended at the end
colnames(size) <- paste(colnames(size), ".size", sep = "")
#viewing the first six rows exchange rates size matrix
head(size)
#Creating an empty matrix with the dimensions of exrates.r
direction <- exrates.r
direction[exrates.r > 0] <- 1     #setting the matrix > 0 = 1
direction[exrates.r < 0] <- -1    #setting the matrix > 0 = -1
direction[exrates.r == 0] <- 0    #setting the matrix == 0 = 0
#setting the column names to the exchange market with ".dir" appended
colnames(direction) <- paste(colnames(exrates.r), ".dir", sep = "")
#Converting into a time series object
#Vector of only dates
#removing the first index of the dates because of the diff function
dates <- exrates$DATE[-1]
#Creating a matrix that has has the percent change, absolute value
#of the percent change, and the whether the foreign exchange
#appreciated, depreciated, or stayed the same
values <- cbind(exrates.r, size, direction)
#Creating the data frame with the dates, returns, size, and direction
exrates.df = data.frame(dates = dates, returns = exrates.r,
size = size, direction = direction)
#Viewing structure of the data to ensure all is looking normal
str(exrates.df)
#Converts the matrix into a time series object
exrates.xts  <- na.omit(as.xts(values, dates))
#Viewing the structure of the time series to make sure nothing is wrong
str(exrates.xts)
#converting from the xts object to a zooreg object
exrates.zr <- na.omit(as.zooreg(exrates.xts))
#Looking at the structure of the of the zooreg object
str(exrates.zr)
readStates <- function(url =
"http://www2.census.gov/programs-surveys/popest/tables/2010-2011/state/totals/nst-est2011-01.csv"){
# Reading the csv and preventing the strings to be read as factors
df <- read.csv(url(url), stringsAsFactors = F)
#Step 2 Clean the dataframe
#--------------------------
#deleting the first 8 rows and the last 5 columns
df <- df[-1:-8, -6:-10]
#deleting the last 7 rows
df <- df[-52:-58,]
#Creating a vector of column names
colNames <- c("stateName", "base2010", "base2011", "Jul2010", "Jul2011")
#Assigning the column names to the data frame
colnames(df) <- colNames
#resetting the row numbers
rownames(df) <- NULL
#Getting rid of the period before all the state names
df$stateName <- gsub("\\.", "", df$stateName)
#Writing a for loop to go through each of the columns 2 through 5
for (col in 2:5){
#Replacing the comma with nothing
df[,col] <- gsub(",", "", df[,col])
#replacing any spaces with nothing
df[,col] <- gsub(" ", "", df[,col])
#Converting the strings to numbers
df[,col] <- as.numeric(df[,col])
}
# returning the data frame
return(df)
}
source('~/Documents/Syracuse/Current Classes/Applied Data Science/HW/HW3/Hyman_Week 3 Homework Assignment.R', echo=TRUE)
dfStates <- readStates()
library(ggplot2)
dfCars <- mtcars
library(ggplot2)
ggplot(dfCars, aes(x = mpg)) + geom_histogram(bins = 5)
ggplot(dfCars, aes(x = mpg)) + geom_histogram(bins = 5, color = "white")
ggplot(dfCars, aes(x = mpg)) + geom_histogram(bins = 5, color = "black", fill = "white")
g <- ggplot(dfCars, aes(x = mpg)) + geom_histogram(bins = 5, color = "black", fill = "white")
g
g + ggtitle("mpg buckets")
g <- ggplot(dfCars, aes(x = mpg)) + geom_histogram(binwidth = 10, color = "black", fill = "white")
g
g <- ggplot(dfCars, aes(x = mpg)) + geom_histogram(binwidth = 5, color = "black", fill = "white")
g
g <- ggplot(dfCars, aes(x = mpg)) + geom_histogram(binwidth = 4, color = "black", fill = "white")
g
timeToNyc <- c(4,4,5,3,5,5,4,4,2)
timeToNyc(Week2<- c(4,5,5,3,8,5,2,4,6,4,3))
timeToNycWeek2<- c(4,5,5,3,8,5,2,4,6,4,3))
timeToNycWeek2<- c(4,5,5,3,8,5,2,4,6,4,3)
week1 <- rep(1, 6)
week2 <- rep(2,6)
time <- c(timeToNyc, timeToNycWeek2)
week <- c(week1, week2)
day <- c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat")
dayOfWeek <- c(day, day)
timeToNyc <- c(4,4.5,3.5,5,4,4.2)
timeToNycWeek2<- c(4.5,5,3.8,5.2,4.6,4.3))
timeToNycWeek2<- c(4.5,5,3.8,5.2,4.6,4.3)
data <- data.frame(dayOfWeek, week, timeToNyc, timeToNycWeek2)
head(data)
df <- data.frame(dayOfWeek, week, timeToNyc, timeToNycWeek2)
ggplot(df, aes(x = day, y = timeToNyc, group = 1)) + geom_line()
data <- data.frame(dayOfWeek, timeToNyc, timeToNycWeek2)
ggplot(df, aes(x = day, y = timeToNyc, group = 1)) + geom_line()
df <- data.frame(dayOfWeek, timeToNyc, timeToNycWeek2)
ggplot(df, aes(x = day, y = timeToNyc, group = 1)) + geom_line()
ggplot(df, aes(x = dayOfWeek, y = timeToNyc, group = 1)) + geom_line()
g <- ggplot(df, aes(x = dayOfWeek, y = timeToNyc, group = 1)) + geom_line()
g <- ggplot(df, aes(x = dayOfWeek, y = timeToNyc, group = 1)) + geom_line(color = "red")
g <- ggplot(df, aes(x = dayOfWeek, y = timeToNyc, group = 1)) + geom_line(color = "red", linetype = "dashed", size = 1.5)
g
g + geom_point()
g
g + geom_point()
g + geom_point(color = "blue", size = 4)
g + geom_point(color = "blue", size = 4, fill = "white") + ylab("Time to NYC (hrs)")
g <- ggplot(df, aes(x = dayOfWeek, y = timeToNyc)) + geom_point()
g
df <- data.frame(dayOfWeek, time, week)
df <- data.frame(days, time, week)
df <- data.frame(day, time, week)
time <- c(timeToNyc, timeToNycWeek2)
dayOfWeek
df <- data.frame(dayOfWeek, time, week)
g <- ggplot(df, aes(dayOfWeek, group = week, color = week)) + geom_line(aes(time))
g
g <- ggplot(df, aes(dayOfWeek, group = week, color = week)) + geom_line(aes(y=time))
g
g <- ggplot(df, aes(dayOfWeek, timeToNyc, group = week, color = week)) + geom_line(aes(y=time))
g
g <- ggplot(df, aes(x=dayOfWeek, group = week, color = week)) + geom_line(aes(y=time))
g
g <- g + ylab("Time to NYC in Hours") + ggtitle("comparing weekly times")
g
g <- ggplot(dfCars, aes(x = factor(0), mpg)) + geom_boxplot()
g
g <- ggplot(dfCars, aes(x = cyl, mpg)) + geom_boxplot()
g
g <- ggplot(dfCars, aes(x = factor(cyl), mpg)) + geom_boxplot()
g
g <- ggplot(dfCars, aes(group = cyl, mpg)) + geom_boxplot()
g + coord_flip()
g <- ggplot(dfCars, aes(group = cyl, y = mpg)) + geom_boxplot() +coord_flip()
g
ggplot(dfCars, aes(x = order(rownames(dfCars), mpg),y = mpg))
ggplot(dfCars, aes(x = order(rownames(dfCars), mpg),y = mpg)) + geom_bar()
ggplot(dfCars, aes(x = order(rownames(dfCars), mpg), y = mpg)) + geom_bar(stat = "identity")
ggplot(dfCars, aes(x = order(row.names(dfCars), mpg), y = mpg)) + geom_bar(stat = "identity")
dfCars$carName <- rownames(dfCars)
order(dfCars$carName, dfCars$mpg)
ggplot(dfCars, aes(x = carNames[order(dfCars$carName, dfCars$mpg)], y = mpg)) + geom_bar(stat = "identity")
ggplot(dfCars, aes(x = carName[order(dfCars$carName, dfCars$mpg)], y = mpg)) + geom_bar(stat = "identity")
ggplot(dfCars, aes(x = dfCars$carName[order(dfCars$carName, dfCars$mpg)], y = mpg)) + geom_bar(stat = "identity")
?reorder
ggplot(dfCars, aes(x = reorder(carName, carName, mpg), y = mpg)) + geom_bar(stat = "identity")
ggplot(dfCars, aes(x = carName[order(mpg)], y = mpg)) + geom_bar(stat = "identity")
ggplot(dfCars, aes(x = reorder(carName, carName, function(x) mpg), y = mpg)) + geom_bar(stat = "identity")
dfCars <- dfCars[order(dfCars$mpg), ]
ggplot(dfCars, aes(x = carName, y = mpg)) + geom_bar(stat = "identity")
dfCars
ggplot(dfCars, aes(x = carName, y = wt)) + geom_bar(stat = "identity")
g <- ggplot(dfCars, aes(x = carName, y = wt)) + geom_bar(stat = "identity")
g + theme(axis.text.x = element_text(angle = 90))
g <- g + theme(axis.text.x = element_text(angle = 90))
g <- ggplot(dfCars, aes(x = mpg, y = carName)) + geom_point(size = 3)
g
g <- ggplot(dfCars, aes(x = mpg, y = reorder(carName, mpg))) + geom_point(size = 3)
g
