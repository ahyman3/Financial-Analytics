#from 0 to 5
p2 <- autoplot.zoo(exrates.zr[,5:8]) + ggtitle(title.size) + ylim(0,5)
#Creating an autocorrelation matrix for each market
#The diagonal is shows the memory in the past for the same market
#The x-axis is the amount of lag
#If x-axis is negative, the exchange market that is listed first
#in the title is the exchange market that is being lagged
acf(coredata(exrates.xts[,1:4]))
#Creating an autocorrelation matrix for the foreign
#exchange markets for columns 5-7 (Size of the
#percent change). Not including the japanese market
#to have larger plots
acf(coredata(exrates.xts[,5:8]))
#Creating a partial
pacf(coredata(exrates.xts[,1:4]))
#Partial autocorrelation on the magnitude of percent change
pacf(coredata(exrates.xts[,5:8]))
data_moments <- function(data) {
library(moments)                            #Package for skewness and kurtosis
library(matrixStats)                        #Package for statistics on matrix columns
mean.r <- colMeans(data)                    #Calculates the mean for each column
median.r <- colMedians(data)                #Calculates the median for each column
sd.r <- colSds(data)                        #Standard deviation for each column
IQR.r <- colIQRs(data)                      #Difference between Q1 and Q3
skewness.r <- skewness(data)                #Skewness for each column
kurtosis.r <- kurtosis(data)                #kurtosis for each column
#Creates a data frame with the statistics for each column
result <- data.frame(mean = mean.r,
median = median.r, std_dev = sd.r,
IQR = IQR.r, skewness = skewness.r,
kurtosis = kurtosis.r)
return(result)
}
#Using the data moments function on the size of the percent change
answer <- data_moments(exrates.xts[,5:8])
#knitting the table to display in a nice formatted table, rounded to 4 decimals
knitr::kable(answer, digits = 4)
#Looking at the mean percent change all the exhange rates
colMeans(exrates.xts[, 1:4])
#Setting a tolerable rate of 95%
exrates.tol.pct <- 0.95
#setting exrates.tol to be the value that has 95% of returns below that value
exrates.tol <- quantile(exrates.df$returns.USD.EUR,
exrates.tol.pct)
#combining variables to create a label that states
#what returns are at the 95%
exrates.tol.label <- paste("Tolerable Rate = ",
round(exrates.tol, 2), "%", sep = "")
#creating a ggplot object with the exrates data frame using the usd to euro exchange rate
#using the cumulative density function to create the plot in a blue color and drawing a
#red vertical line at the 95% and adding text to the plot that the tolerable rate is
#at 95%
p <- ggplot(exrates.df, aes(returns.USD.EUR,
fill = direction.USD.EUR.dir)) +
stat_ecdf(colour = "blue", size = 0.75) +
geom_vline(xintercept = exrates.tol,
colour = "red", size = 1.5) +
annotate("text", x = exrates.tol +
1, y = 0.75, label = exrates.tol.label,
colour = "darkred")
#showing the plot
p
#creating a timeseries for the euro exchange rate
one <- ts(exrates.df$returns.USD.EUR)
#creating a timeseries for the british pound exchange rate
two <- ts(exrates.df$returns.USD.GBP)
#Creating a cross-correlation function to estimate the
#the cross correlation with both positive and negative lag
#with a maximum lag of 20 and having a red confidence interval
ccf(one, two, main = "GBP vs. EUR", lag.max = 20,
xlab = "", ylab = "", ci.col = "red")
#creating a functtion that has inputs of two columns of a
#data frame, a title, the lag, abd the color of the confidence interval on the plot
run_ccf <- function(one, two, main = "one vs. two",
lag = 20, color = "red") {
#If the lengths of the two vectors are not the same length, stop
stopifnot(length(one) == length(two))
#convert the vectors into timeseries
one <- ts(one)
two <- ts(two)
#setting the title to main
main <- main
#Setting the lag to the lag
lag <- lag
#setting the color to the color
color <- color
#creating the cross correlation function
ccf(one, two, main = main, lag.max = lag,
xlab = "", ylab = "", ci.col = color)
# end run_ccf
}
#setting the first vector to the the euro exchange
one <- exrates.df$returns.USD.EUR
#setting the second vector to the GBP exchange
two <- exrates.df$returns.USD.GBP
#creating the title for the figure
title <- "EUR vs. GBP"
#Running the function with the arguments created
run_ccf(one, two, main = title, lag = 20,
color = "red")
#Creating a vector from the euro zoo object
one <- exrates.zr[, 5]
#Creating a vector from the GBP zoo object
two <- exrates.zr[, 6]
#Creating a title for our plot
title <- "EUR vs. GBP: volatility"
#Running the cross correlation function we created
run_ccf(one, two, main = title, lag = 20,
color = "red")
# We see some small raw correlations
# across time with raw returns. More
# revealing, we see volatility of
# correlation clustering using return
# sizes.
#Starting a function that takes in a data frame
corr_rolling <- function(x) {
#getting the number of columns in the data frame
dim <- ncol(x)
#taking the correlation of the data frame and index the lower triangle
#of the square matrix, excluding the diagonal
corr_r <- cor(x)[lower.tri(diag(dim),
diag = FALSE)]
#returning the lower triangle of the correlation matrix
return(corr_r)
}
#Create a function for calculating the rolling volatility
vol_rolling <- function(x) {
#loading the matrix statistics library
library(matrixStats)
#calculating the volatility if the columns of the data frame
vol_r <- colSds(x)
#returning the standard deviations of the columns
return(vol_r)
}
#Creating a matrix of the returns
ALL.r <- exrates.xts[, 1:4]
#Creating a window of 90 days
window <- 90  #reactive({input$window})
#rollapply is applying the corr_rolling function to the All.r data frame
#on a rolling window of 90 days on each column individually
corr_r <- rollapply(ALL.r, width = window,
corr_rolling, align = "right", by.column = FALSE)
#Assigning the column names to the correlations between the columns
colnames(corr_r) <- c("EUR.GBP", "EUR.CNY",
"EUR.JPY", "GBP.CNY", "GBP.JPY",
"CNY.JPY")
#rollapply is applying the vol_rolling function to the All.r data frame
#on a rolling window of 90 days on each column individually
vol_r <- rollapply(ALL.r, width = window,
vol_rolling, align = "right", by.column = FALSE)
#assigning the column names to the vol_r data frame
colnames(vol_r) <- c("EUR.vol", "GBP.vol",
"CNY.vol", "JPY.vol")
#creating a vector that takes the year from the index and just extracts the year
year <- format(index(corr_r), "%Y")
#combining the data frames for the returns, rolling returns correlation, rolling
#volatility correlation, and the year for the date
r_corr_vol <- merge(ALL.r, corr_r, vol_r,
year)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating a vector from 0.05 to 0.95 in which the regression will attempt
#to reduce error from that given quantile at a given x
taus <- seq(0.05, 0.95, 0.05)  # Roger Koenker UIC Bob Hogg and Allen Craig
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating
fit.lm.CNY.JPY <- lm(log(CNY.JPY) ~ log(JPY.vol),
data = r_corr_vol)
.
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#importing the quantile regression library
library(quantreg)
#running a quantile regression to see how the the rolling volatility
# of the japanese yen effects the correlation in exchange rates between the
#yuan and the yen at the quantiles specified in taus and the data provided
#in the r_corr_vol data frame using the log of the correlation and the log
#of the volatility to transform into linear data
fit.rq.CNY.JPY <- rq(log(CNY.JPY) ~ log(JPY.vol),
tau = taus, data = r_corr_vol)
#Creating
fit.lm.CNY.JPY <- lm(log(CNY.JPY) ~ log(JPY.vol),
data = r_corr_vol)
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
CNY.JPY.summary
CNY.JPY.summary <- summary(fit.lm.CNY.JPY,
se = "boot")
CNY.JPY.summary
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
# Some test statements
CNY.JPY.summary <- summary(fit.rq.CNY.JPY,
se = "boot")
CNY.JPY.summary
library(quantreg)
library(magick)
?image_graph
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
geom_quantile(quantiles = c(0.05,
0.95)) + geom_quantile(quantiles = 0.5,
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_quantile
p <- ggplot(data, aes(JPY.vol, CNY.JPY))
mtcars
cars <- mtcars
p <- ggplot(cars, aes(wt, mpg))
?geom_density2d
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
geom_quantile(quantiles = c(0.05,
0.95)) + geom_quantile(quantiles = 0.5,
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_density
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?geom_density_2d
?dev.off
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(log(JPY.vol), log(CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the regression
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(log(JPY.vol), log(CNY.JPY))) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
#library for quantile regression
library(quantreg)
#library for animations
library(magick)
#Setting the resolution of the image to 96 pixels
img <- image_graph(res = 96)
#Creating a list that has the r_corr_vol data frame
#split up by each yeat
datalist <- split(r_corr_vol, r_corr_vol$year)
#using list apply to apply a custom function for each year
out <- lapply(datalist, function(data) {
#creating a plot assigned to the p variable with the yen volatility as
#the x-axis and the yuan and yen correlation y-axis
p <- ggplot(data, aes(JPY.vol, CNY.JPY)) +
#making it a scatterplot and titling it the year
geom_point() + ggtitle(data$year) +
#creating a confidence interval with a solid blue line
#that shows how the 0.05 quantile and 0.95 quantile line
#looks like
geom_quantile(quantiles = c(0.05,
#Plotting the quantile regression at the median with a
#blue londashed line
0.95)) + geom_quantile(quantiles = 0.5,
#Uses contours to show densities from the scatter plot
linetype = "longdash") + geom_density_2d(colour = "red")
print(p)
})
while (!is.null(dev.list())) dev.off()
# img <-
# image_background(image_trim(img),
# 'white')
animation <- image_animate(img, fps = 0.5)
animation
?dev.list
dev.list(()\)
dev.list()
?magick
?image_graph
?image_animate
knitr::opts_chunk$set(echo = TRUE)
library(zoo)      #For creating time series objects
library(xts)      #For time series analysis
library(ggplot2)  #For creating graphics
library(plotly)
#The URL for the exchange data data
URL <- "https://turing.manhattan.edu/~wfoote01/finalytics/data/exrates.csv"
#Reading in the exchange rates and omitting the missing data from the
#url provided by turing.manhattan.edu and keeping the dates as characters
exrates <- na.omit(read.csv("exrates.csv", stringsAsFactors = F))
#Converting the string dates to actual dates
exrates$DATE <- as.Date(exrates$DATE, "%m/%d/%Y")
#Five columns (date, eur2usd, gbp2usd, cny2usd, jpy2usd)
#the data is daily exchange rates
head(exrates)     #Looking at the data
tail(exrates)     #Looking at the end of the data
str(exrates)      #Viewing the structure of the data
#1253 different instances of exchange rates
summary(exrates)  #From 28 Jan 2013 to 26 Jan 2018
# USD to CNY appears to be the most steady
#Using the properties of the natural log to determine
#the percent change in exchange rates
exrates.r <- diff(log(as.matrix(exrates[,-1]))) * 100
head(exrates.r)   #first 6 days of percent change
tail(exrates.r)   #last 6 days of percent change
str(exrates.r)    #Shows there are 4 columns with 1252 instances
#creating a matrix for the volatility of the exchange markets
size <- na.omit(abs(exrates.r))
head(size)        #viewing the first 6 rows of the size matrix
#Creating a vector of names for the matrix that has the same name as
#the exrates matrix, but with ".size" appended at the end
colnames(size) <- paste(colnames(size), ".size", sep = "")
#viewing the first six rows exchange rates size matrix
head(size)
#Creating an empty matrix with the dimensions of exrates.r
direction <- exrates.r
direction[exrates.r > 0] <- 1     #setting the matrix > 0 = 1
direction[exrates.r < 0] <- -1    #setting the matrix > 0 = -1
direction[exrates.r == 0] <- 0    #setting the matrix == 0 = 0
#setting the column names to the exchange market with ".dir" appended
colnames(direction) <- paste(colnames(exrates.r), ".dir", sep = "")
#Converting into a time series object
#Vector of only dates
#removing the first index of the dates because of the diff function
dates <- exrates$DATE[-1]
#Creating a matrix that has has the percent change, absolute value
#of the percent change, and the whether the foreign exchange
#appreciated, depreciated, or stayed the same
values <- cbind(exrates.r, size, direction)
#Creating the data frame with the dates, returns, size, and direction
exrates.df = data.frame(dates = dates, returns = exrates.r,
size = size, direction = direction)
#Viewing structure of the data to ensure all is looking normal
str(exrates.df)
#Converts the matrix into a time series object
exrates.xts  <- na.omit(as.xts(values, dates))
#Viewing the structure of the time series to make sure nothing is wrong
str(exrates.xts)
#converting from the xts object to a zooreg object
exrates.zr <- na.omit(as.zooreg(exrates.xts))
#Looking at the structure of the of the zooreg object
str(exrates.zr)
