---
title: "Market Risk in Metals Market"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}

library(ggplot2)
library(flexdashboard)
library(shiny)
library(QRM)
library(qrmdata)
library(xts)
library(zoo)
library(psych)
library(matrixStats)

# PAGE: Exploratory Analysis

#Removes all objects in this environment to blank out for the dashboard
rm(list = ls())
#Reading in the data
data <- na.omit(read.csv(url("https://turing.manhattan.edu/~wfoote01/finalytics/data/metaldata.csv"), header = TRUE))
#Applies the log difference to the numeric columns in the data matrix and multiplies by 100 to get percentage
data.r <- apply(log(data[,-1]), 2, diff) * 100
#Finding the magnitude of the percent change with absolute value
size <- na.omit(abs(data.r))

#adds .size to the end of the column
colnames(size) <- paste(colnames(size), ".size", sep = "")
#If the returns is positive, make a new matrix have a 1 in that place
#If the returns is negative, put a -1 in that place, otherwise a 0
direction <- ifelse(data.r > 0, 1, ifelse(data.r < 0, -1, 0))
#Adding .dir to the end of the column names in the dirextion data frame
colnames(direction) <- paste(colnames(direction), ".dir", sep = "")
#Making a vector of the dates
dates <- as.Date(data[-1,1], "%m/%d/%Y")
#Making dates characters
dates.chr <- as.character(dates)
#Combining all columns to make a values data frame
values <- cbind(data.r, size, direction)
#Creating tidy data frames
data.df <- data.frame(dates = dates, returns = data.r, size = size, direction = direction)
data.df.nd <- data.frame(dates = dates.chr, returns = data.r, size = size, direction = direction, stringsAsFactors = FALSE)
#Creating a time series object
data.xts <- na.omit(as.xts(values, dates))
#Making a zoo object
data.zr <- as.zooreg(data.xts)
returns <- data.xts


# PAGE: Market risk
#Function to use in roll apply
corr_rolling <- function(x){
  #Number of columns in x
  dim <- ncol(x)
  #calculate the correlation of r, nut only include the the 
  #lower triangle of the correlation matrix because the resulting
  #matrix will be c x c
  corr_r <- cor(x)[lower.tri(diag(dim), diag = FALSE)]
  #Return all teh correlations
  return(corr_r)
}
#Function to use in the rollapply function
vol_rolling <- function(x){
  #Importing the library for matrix statistics
  library(matrixStats)
  #calculate the standard deviation in the column
  vol_r <- colSds(x)
  #return the SDs
  return(vol_r)
}
#making a matrix of only the returns (no dates)
ALL.r <- data.xts[, 1:3]
#Creating a window of 90 days
window <- 90 
#apply the rolling correlation function on the returns data
corr_r <- rollapply(ALL.r, width = window, corr_rolling, align = "right", by.column = FALSE)
#giving column names to the correlation matrix that has the two metals being measured
colnames(corr_r) <- c("nickel.copper", "nickel.aluminium", "copper.aluminium")
#apply the rolling correlation function on the returns data
vol_r <- rollapply(ALL.r, width = window, vol_rolling, align = "right", by.column = FALSE)
#giving the column names to specify they are volatilities being measured
colnames(vol_r) <- c("nickel.vol", "copper.vol", "aluminium.vol")
#Creating a vector that has the dates for all rows
year <- format(index(corr_r), "%Y")
#Creates a dataframe that has all the rolling calculations and all the raw data
#and the year of that piece of data
r_corr_vol <- merge(ALL.r, corr_r, vol_r, year)

#importing library for quantile regression
library(quantreg)
#Creating a vector of quantiles from 0.05 to 0.95 in increments of 0.05
taus <- seq(0.05, 0.95, 0.05)
#Fitting a quantile regression of nickel on copper
fit.rq.nickel.copper <- rq(log(nickel.copper) ~ 
    log(copper.vol), tau = taus, data = r_corr_vol)
#Fitting linear regression on copper and nickel
fit.lm.nickel.copper <- lm(log(nickel.copper) ~ 
    log(copper.vol), data = r_corr_vol)
#Creating a summary of the quantile regreassion fit
ni.cu.summary <- summary(fit.rq.nickel.copper, 
    se = "boot")
#plotting the summary/quantile regression coefficients
plot(ni.cu.summary)

##
#Title for the plot
title.chg <- "Metals Market Percent Changes"
#Plotting the returns for copper, nickel, and aluminum from -5 to 5
autoplot.zoo(data.xts[, 1:3]) + ggtitle(title.chg) + 
    ylim(-5, 5)
#plotting the magnitude of change for the metals
title2 <- "Metals Market Magnitude of Change"
autoplot.zoo(data.xts[, 4:6]) + ggtitle(title2) + 
    ylim(-.5, 5)

#Autocorrelation in returns for the metals
acf(coredata(data.xts[, 1:3]))  # returns

#Autocorrelation for magnitude of returns
acf(coredata(data.xts[, 4:6]))  # sizes

# making time series of nickel returns
one <- ts(data.df$returns.nickel)
# making time series of copper returns
two <- ts(data.df$returns.copper)
#Creating title for ccf plot
title.chg <- "Nickel vs. Copper"
#ccf for nickel and copper
ccf(one, two, main = title.chg, lag.max = 20, 
    xlab = "", ylab = "", ci.col = "red")

#Creating function for repetition
#provide the two vectors, title, lag, and color of confidence interval
run_ccf <- function(one, two, main = title.chg, 
    lag = 20, color = "red") {
    #Stop the function if the vectors are not equal length
    stopifnot(length(one) == length(two))
    #create one time series
    one <- ts(one)
    #creating other time series
    two <- ts(two)
    #Running the cross correlation function
    ccf(one, two, main = main, lag.max = lag, 
        xlab = "", ylab = "", ci.col = color)
    # end run_ccf
}
title <- "nickel-copper"
run_ccf(one, two, main = title, lag = 20, 
    color = "red")

#Running the ccf function for volatilities
# now for volatility (sizes)
#
one <- abs(data.zr[, 4])
two <- abs(data.zr[, 5])
title <- "Nickel-Copper: volatility"
run_ccf(one, two, main = title, lag = 20, 
    color = "red")



#Data Moments for nickel and 
data_moments <- function(data) {
    library(moments)
    library(matrixStats)
    mean.r <- colMeans(data)
    median.r <- colMedians(data)
    sd.r <- colSds(data)
    IQR.r <- colIQRs(data)
    skewness.r <- skewness(data)
    kurtosis.r <- kurtosis(data)
    result <- data.frame(mean = mean.r, 
        median = median.r, std_dev = sd.r, 
        IQR = IQR.r, skewness = skewness.r, 
        kurtosis = kurtosis.r)
    return(result)
}
# Run data moments for the size and directions of all metals
answer <- data_moments(data.xts[, 4:9])
# Build pretty table with 4 digits
answer <- round(answer, 4)
#Knitting the table
knitr::kable(answer)

#Average size in change of nickel
mean(data.xts[, 4])


## 
#Returns of nickel
returns1 <- returns[, 1]
#Naming the column
colnames(returns1) <- "Returns"
#Creating data frame with a column "Distribution" that states
#That this is the historical returns
returns1.df <- data.frame(Returns = returns1[, 
    1], Distribution = rep("Historical", 
    each = length(returns1)))
#95% confidence interval
alpha <- 0.95  # reactive({ifelse(input$alpha.q>1,0.99,ifelse(input$alpha.q<0,0.001,input$alpha.q))})

# finding the value that is at the accepted risk in the returns
VaR.hist <- quantile(returns1, alpha)
#Creating text for the plot that will say what the Value at risk is
VaR.text <- paste("Value at Risk =", 
    round(VaR.hist, 2))

# Determine the max y value of the
# desity plot.  This will be used to
# place the text above the plot
VaR.y <- max(density(returns1.df$Returns)$y)

# Expected Shortfall is mean of values greater than VaR
ES.hist <- mean(returns1[returns1 > 
    VaR.hist])
#Creating text for the expected shortfall
ES.text <- paste("Expected Shortfall =", 
    round(ES.hist, 2))
#Creating a ggplot object with the returns being x and fill being the Distribution
p <- ggplot(returns1.df, aes(x = Returns, 
    fill = Distribution)) + geom_density(alpha = 0.5) + #Making it a density plot
    geom_vline(aes(xintercept = VaR.hist),#Adding vertical line at the VaR
        linetype = "dashed", size = 1, 
        #Adding a vertical line at the expected shortfall
        color = "firebrick1") + geom_vline(aes(xintercept = ES.hist), 
    size = 1, color = "firebrick1") + 
    #adding the text to the plot
    annotate("text", x = 4 + VaR.hist, 
        y = VaR.y * 1.05, label = VaR.text) + 
    annotate("text", x = 3.5 + ES.hist, 
        y = VaR.y * 1.1, label = ES.text) + 
    scale_fill_manual(values = "dodgerblue4")
#Showing the plot
p





```

Column {data-width=650}
-----------------------------------------------------------------------

### Chart A

```{r}

```

Column {data-width=350}
-----------------------------------------------------------------------

### Chart B

```{r}

```

### Chart C

```{r}

```

